{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Parkison Disease USing Classification**"
      ],
      "metadata": {
        "id": "k64kYUkNjt56"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "V4AmtaeBjT0C",
        "outputId": "d0c14319-c0aa-4a86-85aa-ca4fee504894"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-5fb7ba761c58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_addons'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons==0.16.1\n",
        "import tensorflow_addons as tfa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdvaYo06kz_9",
        "outputId": "51c2fef2-2631-431a-f86e-babe04056290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons==0.16.1\n",
            "  Downloading tensorflow_addons-0.16.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons==0.16.1) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.16.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.9.2 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "EPOCHS = 300\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "df = pd.read_csv('/content/Parkinsson disease.csv')"
      ],
      "metadata": {
        "id": "yI0N55Iqjypl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "seed_everything(SEED)"
      ],
      "metadata": {
        "id": "z2SGEnSfkNKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "HD5Q8VzpkQGA",
        "outputId": "bf85d5a2-96d9-426d-c31b-3b0a96af58fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
              "0    phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
              "1    phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
              "2    phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
              "3    phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
              "4    phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
              "..              ...          ...           ...           ...             ...   \n",
              "190  phon_R01_S50_2      174.188       230.978        94.261         0.00459   \n",
              "191  phon_R01_S50_3      209.516       253.017        89.488         0.00564   \n",
              "192  phon_R01_S50_4      174.688       240.005        74.287         0.01360   \n",
              "193  phon_R01_S50_5      198.764       396.961        74.904         0.00740   \n",
              "194  phon_R01_S50_6      214.289       260.277        77.973         0.00567   \n",
              "\n",
              "     MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
              "0             0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
              "1             0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
              "2             0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
              "3             0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
              "4             0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
              "..                ...       ...       ...         ...           ...  ...   \n",
              "190           0.00003   0.00263   0.00259     0.00790       0.04087  ...   \n",
              "191           0.00003   0.00331   0.00292     0.00994       0.02751  ...   \n",
              "192           0.00008   0.00624   0.00564     0.01873       0.02308  ...   \n",
              "193           0.00004   0.00370   0.00390     0.01109       0.02296  ...   \n",
              "194           0.00003   0.00295   0.00317     0.00885       0.01884  ...   \n",
              "\n",
              "     Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
              "0        0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
              "1        0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
              "2        0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
              "3        0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
              "4        0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
              "..           ...      ...     ...     ...       ...       ...       ...   \n",
              "190      0.07008  0.02764  19.517       0  0.448439  0.657899 -6.538586   \n",
              "191      0.04812  0.01810  19.147       0  0.431674  0.683244 -6.195325   \n",
              "192      0.03804  0.10715  17.883       0  0.407567  0.655683 -6.787197   \n",
              "193      0.03794  0.07223  19.020       0  0.451221  0.643956 -6.744577   \n",
              "194      0.03078  0.04398  21.209       0  0.462803  0.664357 -5.724056   \n",
              "\n",
              "      spread2        D2       PPE  \n",
              "0    0.266482  2.301442  0.284654  \n",
              "1    0.335590  2.486855  0.368674  \n",
              "2    0.311173  2.342259  0.332634  \n",
              "3    0.334147  2.405554  0.368975  \n",
              "4    0.234513  2.332180  0.410335  \n",
              "..        ...       ...       ...  \n",
              "190  0.121952  2.657476  0.133050  \n",
              "191  0.129303  2.784312  0.168895  \n",
              "192  0.158453  2.679772  0.131728  \n",
              "193  0.207454  2.138608  0.123306  \n",
              "194  0.190667  2.555477  0.148569  \n",
              "\n",
              "[195 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf15521a-a40d-494b-b6c8-e89b95f5b686\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>MDVP:Fo(Hz)</th>\n",
              "      <th>MDVP:Fhi(Hz)</th>\n",
              "      <th>MDVP:Flo(Hz)</th>\n",
              "      <th>MDVP:Jitter(%)</th>\n",
              "      <th>MDVP:Jitter(Abs)</th>\n",
              "      <th>MDVP:RAP</th>\n",
              "      <th>MDVP:PPQ</th>\n",
              "      <th>Jitter:DDP</th>\n",
              "      <th>MDVP:Shimmer</th>\n",
              "      <th>...</th>\n",
              "      <th>Shimmer:DDA</th>\n",
              "      <th>NHR</th>\n",
              "      <th>HNR</th>\n",
              "      <th>status</th>\n",
              "      <th>RPDE</th>\n",
              "      <th>DFA</th>\n",
              "      <th>spread1</th>\n",
              "      <th>spread2</th>\n",
              "      <th>D2</th>\n",
              "      <th>PPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>phon_R01_S01_1</td>\n",
              "      <td>119.992</td>\n",
              "      <td>157.302</td>\n",
              "      <td>74.997</td>\n",
              "      <td>0.00784</td>\n",
              "      <td>0.00007</td>\n",
              "      <td>0.00370</td>\n",
              "      <td>0.00554</td>\n",
              "      <td>0.01109</td>\n",
              "      <td>0.04374</td>\n",
              "      <td>...</td>\n",
              "      <td>0.06545</td>\n",
              "      <td>0.02211</td>\n",
              "      <td>21.033</td>\n",
              "      <td>1</td>\n",
              "      <td>0.414783</td>\n",
              "      <td>0.815285</td>\n",
              "      <td>-4.813031</td>\n",
              "      <td>0.266482</td>\n",
              "      <td>2.301442</td>\n",
              "      <td>0.284654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>phon_R01_S01_2</td>\n",
              "      <td>122.400</td>\n",
              "      <td>148.650</td>\n",
              "      <td>113.819</td>\n",
              "      <td>0.00968</td>\n",
              "      <td>0.00008</td>\n",
              "      <td>0.00465</td>\n",
              "      <td>0.00696</td>\n",
              "      <td>0.01394</td>\n",
              "      <td>0.06134</td>\n",
              "      <td>...</td>\n",
              "      <td>0.09403</td>\n",
              "      <td>0.01929</td>\n",
              "      <td>19.085</td>\n",
              "      <td>1</td>\n",
              "      <td>0.458359</td>\n",
              "      <td>0.819521</td>\n",
              "      <td>-4.075192</td>\n",
              "      <td>0.335590</td>\n",
              "      <td>2.486855</td>\n",
              "      <td>0.368674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>phon_R01_S01_3</td>\n",
              "      <td>116.682</td>\n",
              "      <td>131.111</td>\n",
              "      <td>111.555</td>\n",
              "      <td>0.01050</td>\n",
              "      <td>0.00009</td>\n",
              "      <td>0.00544</td>\n",
              "      <td>0.00781</td>\n",
              "      <td>0.01633</td>\n",
              "      <td>0.05233</td>\n",
              "      <td>...</td>\n",
              "      <td>0.08270</td>\n",
              "      <td>0.01309</td>\n",
              "      <td>20.651</td>\n",
              "      <td>1</td>\n",
              "      <td>0.429895</td>\n",
              "      <td>0.825288</td>\n",
              "      <td>-4.443179</td>\n",
              "      <td>0.311173</td>\n",
              "      <td>2.342259</td>\n",
              "      <td>0.332634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>phon_R01_S01_4</td>\n",
              "      <td>116.676</td>\n",
              "      <td>137.871</td>\n",
              "      <td>111.366</td>\n",
              "      <td>0.00997</td>\n",
              "      <td>0.00009</td>\n",
              "      <td>0.00502</td>\n",
              "      <td>0.00698</td>\n",
              "      <td>0.01505</td>\n",
              "      <td>0.05492</td>\n",
              "      <td>...</td>\n",
              "      <td>0.08771</td>\n",
              "      <td>0.01353</td>\n",
              "      <td>20.644</td>\n",
              "      <td>1</td>\n",
              "      <td>0.434969</td>\n",
              "      <td>0.819235</td>\n",
              "      <td>-4.117501</td>\n",
              "      <td>0.334147</td>\n",
              "      <td>2.405554</td>\n",
              "      <td>0.368975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>phon_R01_S01_5</td>\n",
              "      <td>116.014</td>\n",
              "      <td>141.781</td>\n",
              "      <td>110.655</td>\n",
              "      <td>0.01284</td>\n",
              "      <td>0.00011</td>\n",
              "      <td>0.00655</td>\n",
              "      <td>0.00908</td>\n",
              "      <td>0.01966</td>\n",
              "      <td>0.06425</td>\n",
              "      <td>...</td>\n",
              "      <td>0.10470</td>\n",
              "      <td>0.01767</td>\n",
              "      <td>19.649</td>\n",
              "      <td>1</td>\n",
              "      <td>0.417356</td>\n",
              "      <td>0.823484</td>\n",
              "      <td>-3.747787</td>\n",
              "      <td>0.234513</td>\n",
              "      <td>2.332180</td>\n",
              "      <td>0.410335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>phon_R01_S50_2</td>\n",
              "      <td>174.188</td>\n",
              "      <td>230.978</td>\n",
              "      <td>94.261</td>\n",
              "      <td>0.00459</td>\n",
              "      <td>0.00003</td>\n",
              "      <td>0.00263</td>\n",
              "      <td>0.00259</td>\n",
              "      <td>0.00790</td>\n",
              "      <td>0.04087</td>\n",
              "      <td>...</td>\n",
              "      <td>0.07008</td>\n",
              "      <td>0.02764</td>\n",
              "      <td>19.517</td>\n",
              "      <td>0</td>\n",
              "      <td>0.448439</td>\n",
              "      <td>0.657899</td>\n",
              "      <td>-6.538586</td>\n",
              "      <td>0.121952</td>\n",
              "      <td>2.657476</td>\n",
              "      <td>0.133050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>phon_R01_S50_3</td>\n",
              "      <td>209.516</td>\n",
              "      <td>253.017</td>\n",
              "      <td>89.488</td>\n",
              "      <td>0.00564</td>\n",
              "      <td>0.00003</td>\n",
              "      <td>0.00331</td>\n",
              "      <td>0.00292</td>\n",
              "      <td>0.00994</td>\n",
              "      <td>0.02751</td>\n",
              "      <td>...</td>\n",
              "      <td>0.04812</td>\n",
              "      <td>0.01810</td>\n",
              "      <td>19.147</td>\n",
              "      <td>0</td>\n",
              "      <td>0.431674</td>\n",
              "      <td>0.683244</td>\n",
              "      <td>-6.195325</td>\n",
              "      <td>0.129303</td>\n",
              "      <td>2.784312</td>\n",
              "      <td>0.168895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>phon_R01_S50_4</td>\n",
              "      <td>174.688</td>\n",
              "      <td>240.005</td>\n",
              "      <td>74.287</td>\n",
              "      <td>0.01360</td>\n",
              "      <td>0.00008</td>\n",
              "      <td>0.00624</td>\n",
              "      <td>0.00564</td>\n",
              "      <td>0.01873</td>\n",
              "      <td>0.02308</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03804</td>\n",
              "      <td>0.10715</td>\n",
              "      <td>17.883</td>\n",
              "      <td>0</td>\n",
              "      <td>0.407567</td>\n",
              "      <td>0.655683</td>\n",
              "      <td>-6.787197</td>\n",
              "      <td>0.158453</td>\n",
              "      <td>2.679772</td>\n",
              "      <td>0.131728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>phon_R01_S50_5</td>\n",
              "      <td>198.764</td>\n",
              "      <td>396.961</td>\n",
              "      <td>74.904</td>\n",
              "      <td>0.00740</td>\n",
              "      <td>0.00004</td>\n",
              "      <td>0.00370</td>\n",
              "      <td>0.00390</td>\n",
              "      <td>0.01109</td>\n",
              "      <td>0.02296</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03794</td>\n",
              "      <td>0.07223</td>\n",
              "      <td>19.020</td>\n",
              "      <td>0</td>\n",
              "      <td>0.451221</td>\n",
              "      <td>0.643956</td>\n",
              "      <td>-6.744577</td>\n",
              "      <td>0.207454</td>\n",
              "      <td>2.138608</td>\n",
              "      <td>0.123306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>phon_R01_S50_6</td>\n",
              "      <td>214.289</td>\n",
              "      <td>260.277</td>\n",
              "      <td>77.973</td>\n",
              "      <td>0.00567</td>\n",
              "      <td>0.00003</td>\n",
              "      <td>0.00295</td>\n",
              "      <td>0.00317</td>\n",
              "      <td>0.00885</td>\n",
              "      <td>0.01884</td>\n",
              "      <td>...</td>\n",
              "      <td>0.03078</td>\n",
              "      <td>0.04398</td>\n",
              "      <td>21.209</td>\n",
              "      <td>0</td>\n",
              "      <td>0.462803</td>\n",
              "      <td>0.664357</td>\n",
              "      <td>-5.724056</td>\n",
              "      <td>0.190667</td>\n",
              "      <td>2.555477</td>\n",
              "      <td>0.148569</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>195 rows × 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf15521a-a40d-494b-b6c8-e89b95f5b686')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cf15521a-a40d-494b-b6c8-e89b95f5b686 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cf15521a-a40d-494b-b6c8-e89b95f5b686');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['status'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9R3VZkWkTkE",
        "outputId": "61c5d76a-95bd-4bae-cc36-1569ade80b47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    147\n",
              "0     48\n",
              "Name: status, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "XTrRlIWAkWji",
        "outputId": "3e2ec3e4-0bb6-4c9a-a0ad-16fee3811116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
              "count   195.000000    195.000000    195.000000      195.000000   \n",
              "mean    154.228641    197.104918    116.324631        0.006220   \n",
              "std      41.390065     91.491548     43.521413        0.004848   \n",
              "min      88.333000    102.145000     65.476000        0.001680   \n",
              "25%     117.572000    134.862500     84.291000        0.003460   \n",
              "50%     148.790000    175.829000    104.315000        0.004940   \n",
              "75%     182.769000    224.205500    140.018500        0.007365   \n",
              "max     260.105000    592.030000    239.170000        0.033160   \n",
              "\n",
              "       MDVP:Jitter(Abs)    MDVP:RAP    MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  \\\n",
              "count        195.000000  195.000000  195.000000  195.000000    195.000000   \n",
              "mean           0.000044    0.003306    0.003446    0.009920      0.029709   \n",
              "std            0.000035    0.002968    0.002759    0.008903      0.018857   \n",
              "min            0.000007    0.000680    0.000920    0.002040      0.009540   \n",
              "25%            0.000020    0.001660    0.001860    0.004985      0.016505   \n",
              "50%            0.000030    0.002500    0.002690    0.007490      0.022970   \n",
              "75%            0.000060    0.003835    0.003955    0.011505      0.037885   \n",
              "max            0.000260    0.021440    0.019580    0.064330      0.119080   \n",
              "\n",
              "       MDVP:Shimmer(dB)  ...  Shimmer:DDA         NHR         HNR      status  \\\n",
              "count        195.000000  ...   195.000000  195.000000  195.000000  195.000000   \n",
              "mean           0.282251  ...     0.046993    0.024847   21.885974    0.753846   \n",
              "std            0.194877  ...     0.030459    0.040418    4.425764    0.431878   \n",
              "min            0.085000  ...     0.013640    0.000650    8.441000    0.000000   \n",
              "25%            0.148500  ...     0.024735    0.005925   19.198000    1.000000   \n",
              "50%            0.221000  ...     0.038360    0.011660   22.085000    1.000000   \n",
              "75%            0.350000  ...     0.060795    0.025640   25.075500    1.000000   \n",
              "max            1.302000  ...     0.169420    0.314820   33.047000    1.000000   \n",
              "\n",
              "             RPDE         DFA     spread1     spread2          D2         PPE  \n",
              "count  195.000000  195.000000  195.000000  195.000000  195.000000  195.000000  \n",
              "mean     0.498536    0.718099   -5.684397    0.226510    2.381826    0.206552  \n",
              "std      0.103942    0.055336    1.090208    0.083406    0.382799    0.090119  \n",
              "min      0.256570    0.574282   -7.964984    0.006274    1.423287    0.044539  \n",
              "25%      0.421306    0.674758   -6.450096    0.174351    2.099125    0.137451  \n",
              "50%      0.495954    0.722254   -5.720868    0.218885    2.361532    0.194052  \n",
              "75%      0.587562    0.761881   -5.046192    0.279234    2.636456    0.252980  \n",
              "max      0.685151    0.825288   -2.434031    0.450493    3.671155    0.527367  \n",
              "\n",
              "[8 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8127f0a4-88fd-46a0-8b1b-44869660140d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MDVP:Fo(Hz)</th>\n",
              "      <th>MDVP:Fhi(Hz)</th>\n",
              "      <th>MDVP:Flo(Hz)</th>\n",
              "      <th>MDVP:Jitter(%)</th>\n",
              "      <th>MDVP:Jitter(Abs)</th>\n",
              "      <th>MDVP:RAP</th>\n",
              "      <th>MDVP:PPQ</th>\n",
              "      <th>Jitter:DDP</th>\n",
              "      <th>MDVP:Shimmer</th>\n",
              "      <th>MDVP:Shimmer(dB)</th>\n",
              "      <th>...</th>\n",
              "      <th>Shimmer:DDA</th>\n",
              "      <th>NHR</th>\n",
              "      <th>HNR</th>\n",
              "      <th>status</th>\n",
              "      <th>RPDE</th>\n",
              "      <th>DFA</th>\n",
              "      <th>spread1</th>\n",
              "      <th>spread2</th>\n",
              "      <th>D2</th>\n",
              "      <th>PPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>195.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>154.228641</td>\n",
              "      <td>197.104918</td>\n",
              "      <td>116.324631</td>\n",
              "      <td>0.006220</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.003306</td>\n",
              "      <td>0.003446</td>\n",
              "      <td>0.009920</td>\n",
              "      <td>0.029709</td>\n",
              "      <td>0.282251</td>\n",
              "      <td>...</td>\n",
              "      <td>0.046993</td>\n",
              "      <td>0.024847</td>\n",
              "      <td>21.885974</td>\n",
              "      <td>0.753846</td>\n",
              "      <td>0.498536</td>\n",
              "      <td>0.718099</td>\n",
              "      <td>-5.684397</td>\n",
              "      <td>0.226510</td>\n",
              "      <td>2.381826</td>\n",
              "      <td>0.206552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>41.390065</td>\n",
              "      <td>91.491548</td>\n",
              "      <td>43.521413</td>\n",
              "      <td>0.004848</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>0.002968</td>\n",
              "      <td>0.002759</td>\n",
              "      <td>0.008903</td>\n",
              "      <td>0.018857</td>\n",
              "      <td>0.194877</td>\n",
              "      <td>...</td>\n",
              "      <td>0.030459</td>\n",
              "      <td>0.040418</td>\n",
              "      <td>4.425764</td>\n",
              "      <td>0.431878</td>\n",
              "      <td>0.103942</td>\n",
              "      <td>0.055336</td>\n",
              "      <td>1.090208</td>\n",
              "      <td>0.083406</td>\n",
              "      <td>0.382799</td>\n",
              "      <td>0.090119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>88.333000</td>\n",
              "      <td>102.145000</td>\n",
              "      <td>65.476000</td>\n",
              "      <td>0.001680</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000680</td>\n",
              "      <td>0.000920</td>\n",
              "      <td>0.002040</td>\n",
              "      <td>0.009540</td>\n",
              "      <td>0.085000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.013640</td>\n",
              "      <td>0.000650</td>\n",
              "      <td>8.441000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.256570</td>\n",
              "      <td>0.574282</td>\n",
              "      <td>-7.964984</td>\n",
              "      <td>0.006274</td>\n",
              "      <td>1.423287</td>\n",
              "      <td>0.044539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>117.572000</td>\n",
              "      <td>134.862500</td>\n",
              "      <td>84.291000</td>\n",
              "      <td>0.003460</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.001660</td>\n",
              "      <td>0.001860</td>\n",
              "      <td>0.004985</td>\n",
              "      <td>0.016505</td>\n",
              "      <td>0.148500</td>\n",
              "      <td>...</td>\n",
              "      <td>0.024735</td>\n",
              "      <td>0.005925</td>\n",
              "      <td>19.198000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.421306</td>\n",
              "      <td>0.674758</td>\n",
              "      <td>-6.450096</td>\n",
              "      <td>0.174351</td>\n",
              "      <td>2.099125</td>\n",
              "      <td>0.137451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>148.790000</td>\n",
              "      <td>175.829000</td>\n",
              "      <td>104.315000</td>\n",
              "      <td>0.004940</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>0.002690</td>\n",
              "      <td>0.007490</td>\n",
              "      <td>0.022970</td>\n",
              "      <td>0.221000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.038360</td>\n",
              "      <td>0.011660</td>\n",
              "      <td>22.085000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.495954</td>\n",
              "      <td>0.722254</td>\n",
              "      <td>-5.720868</td>\n",
              "      <td>0.218885</td>\n",
              "      <td>2.361532</td>\n",
              "      <td>0.194052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>182.769000</td>\n",
              "      <td>224.205500</td>\n",
              "      <td>140.018500</td>\n",
              "      <td>0.007365</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>0.003835</td>\n",
              "      <td>0.003955</td>\n",
              "      <td>0.011505</td>\n",
              "      <td>0.037885</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.060795</td>\n",
              "      <td>0.025640</td>\n",
              "      <td>25.075500</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.587562</td>\n",
              "      <td>0.761881</td>\n",
              "      <td>-5.046192</td>\n",
              "      <td>0.279234</td>\n",
              "      <td>2.636456</td>\n",
              "      <td>0.252980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>260.105000</td>\n",
              "      <td>592.030000</td>\n",
              "      <td>239.170000</td>\n",
              "      <td>0.033160</td>\n",
              "      <td>0.000260</td>\n",
              "      <td>0.021440</td>\n",
              "      <td>0.019580</td>\n",
              "      <td>0.064330</td>\n",
              "      <td>0.119080</td>\n",
              "      <td>1.302000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.169420</td>\n",
              "      <td>0.314820</td>\n",
              "      <td>33.047000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.685151</td>\n",
              "      <td>0.825288</td>\n",
              "      <td>-2.434031</td>\n",
              "      <td>0.450493</td>\n",
              "      <td>3.671155</td>\n",
              "      <td>0.527367</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8127f0a4-88fd-46a0-8b1b-44869660140d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8127f0a4-88fd-46a0-8b1b-44869660140d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8127f0a4-88fd-46a0-8b1b-44869660140d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('name', axis=1)\n",
        "\n",
        "train_df, test_df = train_test_split(df, \n",
        "                                     test_size=0.2, \n",
        "                                     random_state=SEED)\n",
        "train_df, val_df = train_test_split(train_df,\n",
        "                                    test_size=0.2,\n",
        "                                    random_state=SEED)\n",
        "\n",
        "\n",
        "X_train = train_df.drop('status', axis=1).values.astype('float32')\n",
        "y_train = train_df['status'].values.astype('int32')\n",
        "X_val = val_df.drop('status', axis=1).values.astype('float32')\n",
        "y_val = val_df['status'].values.astype('int32')\n",
        "X_test = test_df.drop('status', axis=1).values.astype('float32')\n",
        "y_test = test_df['status'].values.astype('int32')\n",
        "\n",
        "mmsc = MinMaxScaler()\n",
        "X_train = mmsc.fit_transform(X_train) \n",
        "X_val = mmsc.transform(X_val)\n",
        "X_test = mmsc.transform(X_test)\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "PQNZZoAkkZty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build the model\n",
        "shape = X_train.shape[1]\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input((shape,)))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "opt = tfa.optimizers.RectifiedAdam()\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFuup7K-kjTw",
        "outputId": "12b6b007-3cfd-4bd2-c9a3-80c605014b85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 128)               2944      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,842\n",
            "Trainable params: 27,842\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es_callback = tf.keras.callbacks.EarlyStopping(patience=30, verbose=1, restore_best_weights=True)\n",
        "history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, \n",
        "                    validation_data=(X_val, y_val), callbacks=[es_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4KR9tsBknW2",
        "outputId": "8f472923-23c0-4400-b8a5-62d62038e9b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "4/4 [==============================] - 2s 76ms/step - loss: 0.7053 - accuracy: 0.3065 - val_loss: 0.7015 - val_accuracy: 0.4062\n",
            "Epoch 2/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7030 - accuracy: 0.3468 - val_loss: 0.6984 - val_accuracy: 0.4688\n",
            "Epoch 3/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6981 - accuracy: 0.4758 - val_loss: 0.6932 - val_accuracy: 0.5625\n",
            "Epoch 4/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6907 - accuracy: 0.6210 - val_loss: 0.6867 - val_accuracy: 0.6875\n",
            "Epoch 5/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6823 - accuracy: 0.7177 - val_loss: 0.6793 - val_accuracy: 0.7188\n",
            "Epoch 6/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6729 - accuracy: 0.7419 - val_loss: 0.6710 - val_accuracy: 0.7188\n",
            "Epoch 7/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6627 - accuracy: 0.7419 - val_loss: 0.6624 - val_accuracy: 0.7188\n",
            "Epoch 8/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6507 - accuracy: 0.7419 - val_loss: 0.6537 - val_accuracy: 0.7188\n",
            "Epoch 9/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6396 - accuracy: 0.7419 - val_loss: 0.6446 - val_accuracy: 0.7188\n",
            "Epoch 10/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6277 - accuracy: 0.7419 - val_loss: 0.6351 - val_accuracy: 0.7188\n",
            "Epoch 11/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6152 - accuracy: 0.7419 - val_loss: 0.6252 - val_accuracy: 0.7188\n",
            "Epoch 12/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6016 - accuracy: 0.7419 - val_loss: 0.6143 - val_accuracy: 0.7188\n",
            "Epoch 13/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5881 - accuracy: 0.7419 - val_loss: 0.6029 - val_accuracy: 0.7188\n",
            "Epoch 14/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5741 - accuracy: 0.7419 - val_loss: 0.5915 - val_accuracy: 0.7188\n",
            "Epoch 15/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5584 - accuracy: 0.7419 - val_loss: 0.5808 - val_accuracy: 0.7188\n",
            "Epoch 16/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5440 - accuracy: 0.7419 - val_loss: 0.5706 - val_accuracy: 0.7188\n",
            "Epoch 17/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5304 - accuracy: 0.7419 - val_loss: 0.5604 - val_accuracy: 0.7188\n",
            "Epoch 18/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5187 - accuracy: 0.7419 - val_loss: 0.5501 - val_accuracy: 0.7188\n",
            "Epoch 19/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5046 - accuracy: 0.7419 - val_loss: 0.5401 - val_accuracy: 0.7188\n",
            "Epoch 20/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4912 - accuracy: 0.7419 - val_loss: 0.5301 - val_accuracy: 0.7188\n",
            "Epoch 21/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4791 - accuracy: 0.7419 - val_loss: 0.5206 - val_accuracy: 0.7188\n",
            "Epoch 22/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4665 - accuracy: 0.7419 - val_loss: 0.5115 - val_accuracy: 0.7188\n",
            "Epoch 23/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4547 - accuracy: 0.7419 - val_loss: 0.5027 - val_accuracy: 0.7188\n",
            "Epoch 24/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4431 - accuracy: 0.7500 - val_loss: 0.4940 - val_accuracy: 0.7188\n",
            "Epoch 25/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4329 - accuracy: 0.7742 - val_loss: 0.4857 - val_accuracy: 0.7500\n",
            "Epoch 26/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4218 - accuracy: 0.7903 - val_loss: 0.4774 - val_accuracy: 0.8125\n",
            "Epoch 27/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4111 - accuracy: 0.8145 - val_loss: 0.4695 - val_accuracy: 0.8125\n",
            "Epoch 28/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4018 - accuracy: 0.8468 - val_loss: 0.4619 - val_accuracy: 0.8125\n",
            "Epoch 29/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3927 - accuracy: 0.8468 - val_loss: 0.4547 - val_accuracy: 0.8125\n",
            "Epoch 30/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3830 - accuracy: 0.8548 - val_loss: 0.4481 - val_accuracy: 0.8125\n",
            "Epoch 31/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3749 - accuracy: 0.8548 - val_loss: 0.4416 - val_accuracy: 0.8125\n",
            "Epoch 32/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3673 - accuracy: 0.8468 - val_loss: 0.4351 - val_accuracy: 0.8125\n",
            "Epoch 33/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3587 - accuracy: 0.8629 - val_loss: 0.4290 - val_accuracy: 0.8125\n",
            "Epoch 34/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3510 - accuracy: 0.8629 - val_loss: 0.4235 - val_accuracy: 0.8438\n",
            "Epoch 35/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3434 - accuracy: 0.8629 - val_loss: 0.4182 - val_accuracy: 0.8438\n",
            "Epoch 36/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3371 - accuracy: 0.8629 - val_loss: 0.4131 - val_accuracy: 0.8438\n",
            "Epoch 37/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3304 - accuracy: 0.8629 - val_loss: 0.4081 - val_accuracy: 0.8438\n",
            "Epoch 38/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3242 - accuracy: 0.8548 - val_loss: 0.4033 - val_accuracy: 0.8438\n",
            "Epoch 39/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3185 - accuracy: 0.8548 - val_loss: 0.3982 - val_accuracy: 0.8750\n",
            "Epoch 40/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3133 - accuracy: 0.8548 - val_loss: 0.3932 - val_accuracy: 0.8750\n",
            "Epoch 41/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3084 - accuracy: 0.8548 - val_loss: 0.3898 - val_accuracy: 0.8750\n",
            "Epoch 42/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3022 - accuracy: 0.8629 - val_loss: 0.3859 - val_accuracy: 0.8750\n",
            "Epoch 43/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2962 - accuracy: 0.8629 - val_loss: 0.3807 - val_accuracy: 0.8750\n",
            "Epoch 44/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2923 - accuracy: 0.8790 - val_loss: 0.3758 - val_accuracy: 0.8750\n",
            "Epoch 45/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2875 - accuracy: 0.8790 - val_loss: 0.3714 - val_accuracy: 0.8750\n",
            "Epoch 46/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2838 - accuracy: 0.8790 - val_loss: 0.3698 - val_accuracy: 0.8750\n",
            "Epoch 47/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2795 - accuracy: 0.8629 - val_loss: 0.3672 - val_accuracy: 0.8750\n",
            "Epoch 48/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2722 - accuracy: 0.8952 - val_loss: 0.3609 - val_accuracy: 0.8750\n",
            "Epoch 49/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2706 - accuracy: 0.8952 - val_loss: 0.3570 - val_accuracy: 0.8750\n",
            "Epoch 50/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2644 - accuracy: 0.8871 - val_loss: 0.3531 - val_accuracy: 0.8750\n",
            "Epoch 51/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2596 - accuracy: 0.8952 - val_loss: 0.3503 - val_accuracy: 0.8750\n",
            "Epoch 52/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2542 - accuracy: 0.8952 - val_loss: 0.3483 - val_accuracy: 0.8750\n",
            "Epoch 53/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2512 - accuracy: 0.8952 - val_loss: 0.3441 - val_accuracy: 0.8750\n",
            "Epoch 54/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2499 - accuracy: 0.8952 - val_loss: 0.3428 - val_accuracy: 0.8750\n",
            "Epoch 55/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2414 - accuracy: 0.9032 - val_loss: 0.3359 - val_accuracy: 0.8750\n",
            "Epoch 56/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2380 - accuracy: 0.8952 - val_loss: 0.3324 - val_accuracy: 0.8750\n",
            "Epoch 57/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2335 - accuracy: 0.8952 - val_loss: 0.3283 - val_accuracy: 0.8750\n",
            "Epoch 58/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2283 - accuracy: 0.9032 - val_loss: 0.3265 - val_accuracy: 0.8750\n",
            "Epoch 59/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2246 - accuracy: 0.9032 - val_loss: 0.3221 - val_accuracy: 0.8750\n",
            "Epoch 60/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2202 - accuracy: 0.9032 - val_loss: 0.3187 - val_accuracy: 0.8750\n",
            "Epoch 61/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2166 - accuracy: 0.8952 - val_loss: 0.3155 - val_accuracy: 0.8750\n",
            "Epoch 62/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2153 - accuracy: 0.9032 - val_loss: 0.3097 - val_accuracy: 0.8750\n",
            "Epoch 63/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2078 - accuracy: 0.9032 - val_loss: 0.3064 - val_accuracy: 0.8750\n",
            "Epoch 64/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2046 - accuracy: 0.9032 - val_loss: 0.3033 - val_accuracy: 0.8750\n",
            "Epoch 65/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2006 - accuracy: 0.9032 - val_loss: 0.2994 - val_accuracy: 0.8750\n",
            "Epoch 66/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1954 - accuracy: 0.9113 - val_loss: 0.2939 - val_accuracy: 0.8750\n",
            "Epoch 67/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1923 - accuracy: 0.9032 - val_loss: 0.2890 - val_accuracy: 0.8750\n",
            "Epoch 68/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1878 - accuracy: 0.9032 - val_loss: 0.2848 - val_accuracy: 0.8750\n",
            "Epoch 69/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1834 - accuracy: 0.9194 - val_loss: 0.2819 - val_accuracy: 0.9062\n",
            "Epoch 70/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1804 - accuracy: 0.9194 - val_loss: 0.2812 - val_accuracy: 0.8750\n",
            "Epoch 71/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1773 - accuracy: 0.9274 - val_loss: 0.2735 - val_accuracy: 0.9062\n",
            "Epoch 72/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1769 - accuracy: 0.9194 - val_loss: 0.2686 - val_accuracy: 0.8750\n",
            "Epoch 73/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1670 - accuracy: 0.9274 - val_loss: 0.2656 - val_accuracy: 0.9062\n",
            "Epoch 74/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1689 - accuracy: 0.9274 - val_loss: 0.2668 - val_accuracy: 0.8750\n",
            "Epoch 75/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1627 - accuracy: 0.9194 - val_loss: 0.2559 - val_accuracy: 0.8750\n",
            "Epoch 76/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1597 - accuracy: 0.9355 - val_loss: 0.2534 - val_accuracy: 0.8750\n",
            "Epoch 77/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1548 - accuracy: 0.9274 - val_loss: 0.2499 - val_accuracy: 0.8750\n",
            "Epoch 78/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1507 - accuracy: 0.9355 - val_loss: 0.2477 - val_accuracy: 0.8750\n",
            "Epoch 79/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1476 - accuracy: 0.9355 - val_loss: 0.2407 - val_accuracy: 0.9062\n",
            "Epoch 80/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1459 - accuracy: 0.9355 - val_loss: 0.2389 - val_accuracy: 0.8750\n",
            "Epoch 81/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1427 - accuracy: 0.9435 - val_loss: 0.2331 - val_accuracy: 0.9062\n",
            "Epoch 82/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1355 - accuracy: 0.9435 - val_loss: 0.2329 - val_accuracy: 0.8750\n",
            "Epoch 83/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1401 - accuracy: 0.9516 - val_loss: 0.2362 - val_accuracy: 0.8750\n",
            "Epoch 84/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1356 - accuracy: 0.9435 - val_loss: 0.2227 - val_accuracy: 0.8750\n",
            "Epoch 85/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1301 - accuracy: 0.9516 - val_loss: 0.2192 - val_accuracy: 0.8750\n",
            "Epoch 86/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1250 - accuracy: 0.9435 - val_loss: 0.2180 - val_accuracy: 0.8750\n",
            "Epoch 87/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1238 - accuracy: 0.9597 - val_loss: 0.2144 - val_accuracy: 0.8750\n",
            "Epoch 88/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1178 - accuracy: 0.9516 - val_loss: 0.2085 - val_accuracy: 0.9062\n",
            "Epoch 89/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1168 - accuracy: 0.9516 - val_loss: 0.2042 - val_accuracy: 0.9062\n",
            "Epoch 90/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1135 - accuracy: 0.9516 - val_loss: 0.2005 - val_accuracy: 0.9062\n",
            "Epoch 91/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1101 - accuracy: 0.9597 - val_loss: 0.1977 - val_accuracy: 0.9062\n",
            "Epoch 92/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1085 - accuracy: 0.9597 - val_loss: 0.1932 - val_accuracy: 0.9062\n",
            "Epoch 93/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1064 - accuracy: 0.9597 - val_loss: 0.1920 - val_accuracy: 0.9375\n",
            "Epoch 94/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1034 - accuracy: 0.9677 - val_loss: 0.1878 - val_accuracy: 0.9375\n",
            "Epoch 95/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1006 - accuracy: 0.9597 - val_loss: 0.1851 - val_accuracy: 0.9062\n",
            "Epoch 96/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0998 - accuracy: 0.9597 - val_loss: 0.1783 - val_accuracy: 0.9375\n",
            "Epoch 97/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0962 - accuracy: 0.9677 - val_loss: 0.1766 - val_accuracy: 0.9375\n",
            "Epoch 98/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0943 - accuracy: 0.9677 - val_loss: 0.1728 - val_accuracy: 0.9375\n",
            "Epoch 99/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0909 - accuracy: 0.9597 - val_loss: 0.1705 - val_accuracy: 0.9062\n",
            "Epoch 100/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0893 - accuracy: 0.9677 - val_loss: 0.1668 - val_accuracy: 0.9375\n",
            "Epoch 101/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0901 - accuracy: 0.9677 - val_loss: 0.1639 - val_accuracy: 0.9688\n",
            "Epoch 102/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0846 - accuracy: 0.9677 - val_loss: 0.1607 - val_accuracy: 0.9688\n",
            "Epoch 103/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0831 - accuracy: 0.9677 - val_loss: 0.1577 - val_accuracy: 0.9375\n",
            "Epoch 104/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0811 - accuracy: 0.9677 - val_loss: 0.1559 - val_accuracy: 0.9375\n",
            "Epoch 105/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0824 - accuracy: 0.9677 - val_loss: 0.1546 - val_accuracy: 1.0000\n",
            "Epoch 106/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0810 - accuracy: 0.9677 - val_loss: 0.1520 - val_accuracy: 0.9375\n",
            "Epoch 107/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0750 - accuracy: 0.9677 - val_loss: 0.1456 - val_accuracy: 1.0000\n",
            "Epoch 108/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0745 - accuracy: 0.9677 - val_loss: 0.1428 - val_accuracy: 1.0000\n",
            "Epoch 109/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0721 - accuracy: 0.9677 - val_loss: 0.1401 - val_accuracy: 1.0000\n",
            "Epoch 110/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0696 - accuracy: 0.9677 - val_loss: 0.1420 - val_accuracy: 0.9688\n",
            "Epoch 111/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0706 - accuracy: 0.9677 - val_loss: 0.1396 - val_accuracy: 0.9688\n",
            "Epoch 112/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0643 - accuracy: 0.9758 - val_loss: 0.1373 - val_accuracy: 1.0000\n",
            "Epoch 113/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0656 - accuracy: 0.9839 - val_loss: 0.1338 - val_accuracy: 1.0000\n",
            "Epoch 114/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0630 - accuracy: 0.9677 - val_loss: 0.1331 - val_accuracy: 1.0000\n",
            "Epoch 115/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0615 - accuracy: 0.9677 - val_loss: 0.1300 - val_accuracy: 1.0000\n",
            "Epoch 116/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0608 - accuracy: 0.9758 - val_loss: 0.1244 - val_accuracy: 1.0000\n",
            "Epoch 117/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0582 - accuracy: 0.9677 - val_loss: 0.1227 - val_accuracy: 1.0000\n",
            "Epoch 118/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0567 - accuracy: 0.9758 - val_loss: 0.1206 - val_accuracy: 1.0000\n",
            "Epoch 119/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0539 - accuracy: 0.9919 - val_loss: 0.1181 - val_accuracy: 1.0000\n",
            "Epoch 120/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0525 - accuracy: 0.9839 - val_loss: 0.1145 - val_accuracy: 1.0000\n",
            "Epoch 121/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0521 - accuracy: 0.9758 - val_loss: 0.1129 - val_accuracy: 1.0000\n",
            "Epoch 122/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0507 - accuracy: 0.9839 - val_loss: 0.1118 - val_accuracy: 1.0000\n",
            "Epoch 123/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0502 - accuracy: 0.9839 - val_loss: 0.1106 - val_accuracy: 1.0000\n",
            "Epoch 124/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0465 - accuracy: 0.9919 - val_loss: 0.1099 - val_accuracy: 1.0000\n",
            "Epoch 125/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0476 - accuracy: 0.9919 - val_loss: 0.1079 - val_accuracy: 1.0000\n",
            "Epoch 126/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0441 - accuracy: 0.9919 - val_loss: 0.1025 - val_accuracy: 1.0000\n",
            "Epoch 127/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0450 - accuracy: 0.9919 - val_loss: 0.1054 - val_accuracy: 1.0000\n",
            "Epoch 128/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0419 - accuracy: 0.9919 - val_loss: 0.1012 - val_accuracy: 1.0000\n",
            "Epoch 129/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0430 - accuracy: 0.9919 - val_loss: 0.0999 - val_accuracy: 1.0000\n",
            "Epoch 130/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 1.0000\n",
            "Epoch 131/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0411 - accuracy: 0.9919 - val_loss: 0.0958 - val_accuracy: 1.0000\n",
            "Epoch 132/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0376 - accuracy: 0.9919 - val_loss: 0.0951 - val_accuracy: 1.0000\n",
            "Epoch 133/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0373 - accuracy: 0.9919 - val_loss: 0.0903 - val_accuracy: 1.0000\n",
            "Epoch 134/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 1.0000\n",
            "Epoch 135/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0343 - accuracy: 0.9919 - val_loss: 0.0860 - val_accuracy: 1.0000\n",
            "Epoch 136/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 1.0000\n",
            "Epoch 137/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.0828 - val_accuracy: 1.0000\n",
            "Epoch 138/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.0812 - val_accuracy: 1.0000\n",
            "Epoch 139/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0340 - accuracy: 0.9919 - val_loss: 0.0814 - val_accuracy: 1.0000\n",
            "Epoch 140/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 0.9688\n",
            "Epoch 141/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.0817 - val_accuracy: 1.0000\n",
            "Epoch 142/300\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 1.0000\n",
            "Epoch 143/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 1.0000\n",
            "Epoch 144/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 0.9688\n",
            "Epoch 145/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 1.0000\n",
            "Epoch 146/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
            "Epoch 147/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.0718 - val_accuracy: 1.0000\n",
            "Epoch 148/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.0709 - val_accuracy: 1.0000\n",
            "Epoch 149/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 1.0000\n",
            "Epoch 150/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.0721 - val_accuracy: 0.9688\n",
            "Epoch 151/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 1.0000\n",
            "Epoch 152/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.0668 - val_accuracy: 1.0000\n",
            "Epoch 153/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 0.9688\n",
            "Epoch 154/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.0649 - val_accuracy: 1.0000\n",
            "Epoch 155/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0640 - val_accuracy: 1.0000\n",
            "Epoch 156/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.0653 - val_accuracy: 1.0000\n",
            "Epoch 157/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 1.0000\n",
            "Epoch 158/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.0636 - val_accuracy: 1.0000\n",
            "Epoch 159/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.0623 - val_accuracy: 1.0000\n",
            "Epoch 160/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.0634 - val_accuracy: 1.0000\n",
            "Epoch 161/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0611 - val_accuracy: 0.9688\n",
            "Epoch 162/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0625 - val_accuracy: 0.9688\n",
            "Epoch 163/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0595 - val_accuracy: 1.0000\n",
            "Epoch 164/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0584 - val_accuracy: 1.0000\n",
            "Epoch 165/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0571 - val_accuracy: 1.0000\n",
            "Epoch 166/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0573 - val_accuracy: 1.0000\n",
            "Epoch 167/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9688\n",
            "Epoch 168/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0559 - val_accuracy: 1.0000\n",
            "Epoch 169/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0555 - val_accuracy: 0.9688\n",
            "Epoch 170/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0570 - val_accuracy: 0.9688\n",
            "Epoch 171/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0544 - val_accuracy: 1.0000\n",
            "Epoch 172/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 0.9688\n",
            "Epoch 173/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0555 - val_accuracy: 0.9688\n",
            "Epoch 174/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0544 - val_accuracy: 0.9688\n",
            "Epoch 175/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9688\n",
            "Epoch 176/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9688\n",
            "Epoch 177/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9688\n",
            "Epoch 178/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0579 - val_accuracy: 0.9688\n",
            "Epoch 179/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0578 - val_accuracy: 0.9688\n",
            "Epoch 180/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 1.0000\n",
            "Epoch 181/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 1.0000\n",
            "Epoch 182/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 0.9688\n",
            "Epoch 183/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 0.9688\n",
            "Epoch 184/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0554 - val_accuracy: 0.9688\n",
            "Epoch 185/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9688\n",
            "Epoch 186/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9688\n",
            "Epoch 187/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9688\n",
            "Epoch 188/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 0.9688\n",
            "Epoch 189/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0555 - val_accuracy: 0.9688\n",
            "Epoch 190/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9688\n",
            "Epoch 191/300\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9688\n",
            "Epoch 192/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 0.9688\n",
            "Epoch 193/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0546 - val_accuracy: 0.9688\n",
            "Epoch 194/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9688\n",
            "Epoch 195/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9688\n",
            "Epoch 196/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9688\n",
            "Epoch 197/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9688\n",
            "Epoch 198/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9688\n",
            "Epoch 199/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9688\n",
            "Epoch 200/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9688\n",
            "Epoch 201/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9688\n",
            "Epoch 202/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9688\n",
            "Epoch 203/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9688\n",
            "Epoch 204/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9688\n",
            "Epoch 205/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9688\n",
            "Epoch 206/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9688\n",
            "Epoch 207/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9688\n",
            "Epoch 208/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.9688\n",
            "Epoch 209/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9688\n",
            "Epoch 210/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9688\n",
            "Epoch 211/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9688\n",
            "Epoch 212/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9688\n",
            "Epoch 213/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9688\n",
            "Epoch 214/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9688\n",
            "Epoch 215/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9688\n",
            "Epoch 216/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9688\n",
            "Epoch 217/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 0.9688\n",
            "Epoch 218/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9688\n",
            "Epoch 219/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9688\n",
            "Epoch 220/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9688\n",
            "Epoch 221/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9688\n",
            "Epoch 222/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9688\n",
            "Epoch 223/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9688\n",
            "Epoch 224/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9688\n",
            "Epoch 225/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9688\n",
            "Epoch 226/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9688\n",
            "Epoch 227/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9688\n",
            "Epoch 228/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9688\n",
            "Epoch 229/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9688\n",
            "Epoch 230/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9688\n",
            "Epoch 231/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 0.9688\n",
            "Epoch 232/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 0.9688\n",
            "Epoch 233/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 0.9688\n",
            "Epoch 234/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9688\n",
            "Epoch 235/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 0.9688\n",
            "Epoch 236/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9688\n",
            "Epoch 237/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 0.9688\n",
            "Epoch 238/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9688\n",
            "Epoch 239/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9688\n",
            "Epoch 240/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9688\n",
            "Epoch 241/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9688\n",
            "Epoch 242/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9688\n",
            "Epoch 243/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 0.9688\n",
            "Epoch 244/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9688\n",
            "Epoch 245/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9688\n",
            "Epoch 246/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9688\n",
            "Epoch 247/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 0.9688\n",
            "Epoch 248/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9688\n",
            "Epoch 249/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9688\n",
            "Epoch 250/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9688\n",
            "Epoch 251/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9688\n",
            "Epoch 252/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9688\n",
            "Epoch 253/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9688\n",
            "Epoch 254/300\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 224.\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9688\n",
            "Epoch 254: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history)[['accuracy', 'val_accuracy']].plot()\n",
        "pd.DataFrame(history.history)[['loss', 'val_loss']].plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "2nEyza_Nk8UN",
        "outputId": "0736c7fc-227e-4679-ded1-af41d1f5bfb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYxZuQV4lHwr",
        "outputId": "ede61bdf-70c6-4416-e65a-ab839a1272f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1798 - accuracy: 0.9487\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.17980420589447021, 0.9487179517745972]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5TakXKBHlYvc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}